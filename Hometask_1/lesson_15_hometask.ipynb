{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a27d7227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eafc87e-ee11-4a90-a352-0a547a6b39ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews \n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cdbe710-a815-4604-913f-5ba7a2908137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of texts_neg = 5,331\n",
      "\n",
      " simplistic , silly and tedious . \n",
      "\n",
      " it's so laddish and juvenile , only teenage boys could possibly find it funny . \n",
      "\n",
      " exploitative and largely devoid of the depth or sophistication that would make watching such a graphic treatment of the crimes bearable . \n",
      "\n",
      " [garbus] discards the potential for pathological study , exhuming instead , the skewed melodrama of the circumstantial situation . \n",
      "\n",
      " a visually flashy but narratively opaque and emotionally vapid exercise in style and mystification . \n"
     ]
    }
   ],
   "source": [
    "fn='rt-polarity.neg'\n",
    "with open(fn, \"r\",encoding='utf-8', errors='ignore') as f: # some invalid symbols encountered \n",
    "    content = f.read()  \n",
    "texts_neg=  content.splitlines()\n",
    "print ('len of texts_neg = {:,}'.format (len(texts_neg)))\n",
    "for review in texts_neg[:5]:\n",
    "    print ( '\\n', review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffcbc876-72d5-40b8-8fde-5b494108af59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of texts_pos = 5,331\n",
      "\n",
      " the rock is destined to be the 21st century's new \" conan \" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal . \n",
      "\n",
      " the gorgeously elaborate continuation of \" the lord of the rings \" trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson's expanded vision of j . r . r . tolkien's middle-earth . \n",
      "\n",
      " effective but too-tepid biopic\n",
      "\n",
      " if you sometimes like to go to the movies to have fun , wasabi is a good place to start . \n",
      "\n",
      " emerges as something rare , an issue movie that's so honest and keenly observed that it doesn't feel like one . \n"
     ]
    }
   ],
   "source": [
    "fn='rt-polarity.pos'\n",
    "\n",
    "with open(fn, \"r\",encoding='utf-8', errors='ignore') as f:\n",
    "    content = f.read()\n",
    "texts_pos=  content.splitlines()\n",
    "print ('len of texts_pos = {:,}'.format (len(texts_pos)))\n",
    "for review in texts_pos[:5]:\n",
    "    print ('\\n', review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1663c6b-430e-4166-9e8a-bd3dc889178f",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_df = pd.DataFrame({'text':texts_pos, 'label':np.ones(len(texts_pos), dtype=int)})\n",
    "negative_df = pd.DataFrame({'text':texts_neg, 'label':np.zeros(len(texts_neg), dtype=int)})\n",
    "general_df = pd.concat([positive_df, negative_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b60db85-5125-499d-b098-64739f22c6e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the rock is destined to be the 21st century's ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the gorgeously elaborate continuation of \" the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>effective but too-tepid biopic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if you sometimes like to go to the movies to h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>emerges as something rare , an issue movie tha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10657</th>\n",
       "      <td>a terrible movie that some people will neverth...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10658</th>\n",
       "      <td>there are many definitions of 'time waster' bu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10659</th>\n",
       "      <td>as it stands , crocodile hunter has the hurrie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10660</th>\n",
       "      <td>the thing looks like a made-for-home-video qui...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10661</th>\n",
       "      <td>enigma is well-made , but it's just too dry an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10662 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      the rock is destined to be the 21st century's ...      1\n",
       "1      the gorgeously elaborate continuation of \" the...      1\n",
       "2                         effective but too-tepid biopic      1\n",
       "3      if you sometimes like to go to the movies to h...      1\n",
       "4      emerges as something rare , an issue movie tha...      1\n",
       "...                                                  ...    ...\n",
       "10657  a terrible movie that some people will neverth...      0\n",
       "10658  there are many definitions of 'time waster' bu...      0\n",
       "10659  as it stands , crocodile hunter has the hurrie...      0\n",
       "10660  the thing looks like a made-for-home-video qui...      0\n",
       "10661  enigma is well-made , but it's just too dry an...      0\n",
       "\n",
       "[10662 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "general_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ff861cf-c68b-4a6f-b6ec-36fedce381c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(general_df['text'], general_df['label'], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fbcce56f-9352-437b-8bc5-ad5738461862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features samples:\n",
      "['10', 'filmmaking', 'on an', 'tour de']\n",
      "\n",
      "len of features 6,637\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(min_df=5, max_features=50000, ngram_range=(1,2)).fit(X_train) # Fit the CountVectorizer to the training data\n",
    "print('features samples:\\n{}'.format(vect.get_feature_names()[::2000])) # display each 2000-th feature \n",
    "print ('\\nlen of features {:,}'.format(len(vect.get_feature_names())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0e541930-935f-465f-b28d-77d56df1798f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7996x6637 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 153101 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectorized = vect.transform(X_train) # indeces of existing words from vocabulary and their count in current text\n",
    "X_train_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f3be9ba-8272-4690-a2b0-e5264fd1c479",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter=2000).fit(X_train_vectorized, y_train) # Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b9a3d776-704b-4d70-a240-8637585ecbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1:  0.7507507507507508\n",
      "AUC:  0.8297838556432501\n"
     ]
    }
   ],
   "source": [
    "predictions = clf.predict(vect.transform(X_test)) # Predict the transformed test documents\n",
    "print('f1: ', f1_score(y_test, predictions)) \n",
    "scores = clf.decision_function(vect.transform(X_test)) \n",
    "print('AUC: ', roc_auc_score(y_test, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d827f478-8267-4445-a326-931df1e743ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 6637),\n",
       " (6637,),\n",
       " [-2.126507615515334,\n",
       "  -1.7118468955443682,\n",
       "  -1.6742039220589116,\n",
       "  -1.6248761513916739,\n",
       "  -1.6079779191482997,\n",
       "  -1.6065869617048836,\n",
       "  -1.5971901010318146,\n",
       "  -1.539170632535987,\n",
       "  -1.5390690413009651,\n",
       "  -1.5204754204213107],\n",
       " [1.3923600940593244,\n",
       "  1.399524092660697,\n",
       "  1.4250090757216813,\n",
       "  1.4345771883472216,\n",
       "  1.4421737057980855,\n",
       "  1.4522535625679653,\n",
       "  1.4794854216795585,\n",
       "  1.5392297920725193,\n",
       "  1.5534451510195055,\n",
       "  1.6044960938854536])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = np.array(vect.get_feature_names())\n",
    "sorted_coef_index = clf.coef_[0].argsort() # ascending  [0] is just squeeze from shape (1,n)\n",
    "clf.coef_.shape, clf.coef_[0].shape, sorted(clf.coef_[0])[:10], sorted(clf.coef_[0])[-11:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "73bbeebf-9be8-40dc-82d1-c541f6079174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest coefs:\n",
      "['dull' 'badly' 'boring' 'tedious' 'incoherent' 'disappointment' 'lacks'\n",
      " 'tv' 'mediocre' 'stupid']\n",
      "\n",
      "Largest Coefs: \n",
      "['better than' 'masterpiece' 'powerful' 'remarkable' 'works' 'solid'\n",
      " 'enjoyable' 'warm' 'engrossing' 'unexpected']\n"
     ]
    }
   ],
   "source": [
    "print('Smallest coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))\n",
    "# model.coef_[0][sorted_coef_index[0]] the smallest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274036c4-dca5-4aae-bb7d-1a4d4d85263a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
